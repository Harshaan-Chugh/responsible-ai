{
    "name": "adversarial_classification_art",
    "display_name" : "Adversarial Classification (ART) Metrics",
    "compatibility": {"task_type": ["classification"],
                      "data_type": ["Numeric"],
                      "output_requirements": ["predict"],
                      "dataset_requirements": ["X", "y"]},
    "src": "art",
    "dependency_list": [],
    "tags": ["robustness", "Adversarial"],
    "complexity_class": "polynomial",
    "metrics": {
        "clever_t_l1": {
            "display_name": "Targeted L1 CLEVER",
            "type": "Numeric",
            "tags": [],
            "has_range": true,
            "range": [0, null],
            "explanation": "A lower bound for Targeted L1 perturbations to trick the classifier.\nL1 attacks are bounded by the total sum of perturbations.",
            "citation": "@misc{https://doi.org/10.48550/arxiv.1801.10578,\n  doi = {10.48550/ARXIV.1801.10578},\n  \n  url = {https://arxiv.org/abs/1801.10578},\n  \n  author = {Weng, Tsui-Wei and Zhang, Huan and Chen, Pin-Yu and Yi, Jinfeng and Su, Dong and Gao, Yupeng and Hsieh, Cho-Jui and Daniel, Luca},\n  \n  keywords = {Machine Learning (stat.ML), Cryptography and Security (cs.CR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  \n  title = {Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach},\n  \n  publisher = {arXiv},\n  \n  year = {2018},\n  \n  copyright = {arXiv.org perpetual, non-exclusive license}\n}\n"
        },
        "clever_t_l2": {
            "display_name": "Targeted L2 CLEVER",
            "type": "Numeric",
            "tags": [],
            "has_range": true,
            "range": [0, null],
            "explanation": "A lower bound for Targeted L2 perturbations to trick the classifier.\nL2 attacks are bounded by the euclidean distance of the perturbation.",
            "citation": "@misc{https://doi.org/10.48550/arxiv.1801.10578,\n  doi = {10.48550/ARXIV.1801.10578},\n  \n  url = {https://arxiv.org/abs/1801.10578},\n  \n  author = {Weng, Tsui-Wei and Zhang, Huan and Chen, Pin-Yu and Yi, Jinfeng and Su, Dong and Gao, Yupeng and Hsieh, Cho-Jui and Daniel, Luca},\n  \n  keywords = {Machine Learning (stat.ML), Cryptography and Security (cs.CR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  \n  title = {Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach},\n  \n  publisher = {arXiv},\n  \n  year = {2018},\n  \n  copyright = {arXiv.org perpetual, non-exclusive license}\n}\n"
        },
        "clever_t_li": {
            "display_name": "Targeted Li CLEVER",
            "type": "Numeric",
            "tags": [],
            "has_range": true,
            "range": [0, null],
            "explanation": "A lower bound for Targeted Li perturbations to trick the classifier.\nLi attacks are bounded by the maximum value of the perturbation.",
            "citation": "@misc{https://doi.org/10.48550/arxiv.1801.10578,\n  doi = {10.48550/ARXIV.1801.10578},\n  \n  url = {https://arxiv.org/abs/1801.10578},\n  \n  author = {Weng, Tsui-Wei and Zhang, Huan and Chen, Pin-Yu and Yi, Jinfeng and Su, Dong and Gao, Yupeng and Hsieh, Cho-Jui and Daniel, Luca},\n  \n  keywords = {Machine Learning (stat.ML), Cryptography and Security (cs.CR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  \n  title = {Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach},\n  \n  publisher = {arXiv},\n  \n  year = {2018},\n  \n  copyright = {arXiv.org perpetual, non-exclusive license}\n}\n"
        },
        "clever_u_l1": {
            "display_name": "Untargeted L1 CLEVER",
            "type": "Numeric",
            "tags": [],
            "has_range": true,
            "range": [0, null],
            "explanation": "A lower bound for Untargeted L1 perturbations to trick the classifier.\nL1 attacks are bounded by the total sum of perturbations.",,
            "citation": "@misc{https://doi.org/10.48550/arxiv.1801.10578,\n  doi = {10.48550/ARXIV.1801.10578},\n  \n  url = {https://arxiv.org/abs/1801.10578},\n  \n  author = {Weng, Tsui-Wei and Zhang, Huan and Chen, Pin-Yu and Yi, Jinfeng and Su, Dong and Gao, Yupeng and Hsieh, Cho-Jui and Daniel, Luca},\n  \n  keywords = {Machine Learning (stat.ML), Cryptography and Security (cs.CR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  \n  title = {Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach},\n  \n  publisher = {arXiv},\n  \n  year = {2018},\n  \n  copyright = {arXiv.org perpetual, non-exclusive license}\n}\n"
        },
        "clever_u_l2": {
            "display_name": "Untargeted L2 CLEVER",
            "type": "Numeric",
            "tags": [],
            "has_range": true,
            "range": [0, null],
            "explanation": "A lower bound for Untargeted L2 perturbations to trick the classifier.\nL2 attacks are bounded by the euclidean distance of the perturbation.",,
            "citation": "@misc{https://doi.org/10.48550/arxiv.1801.10578,\n  doi = {10.48550/ARXIV.1801.10578},\n  \n  url = {https://arxiv.org/abs/1801.10578},\n  \n  author = {Weng, Tsui-Wei and Zhang, Huan and Chen, Pin-Yu and Yi, Jinfeng and Su, Dong and Gao, Yupeng and Hsieh, Cho-Jui and Daniel, Luca},\n  \n  keywords = {Machine Learning (stat.ML), Cryptography and Security (cs.CR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  \n  title = {Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach},\n  \n  publisher = {arXiv},\n  \n  year = {2018},\n  \n  copyright = {arXiv.org perpetual, non-exclusive license}\n}\n"
        },
        "clever_u_li": {
            "display_name": "Untargeted Li CLEVER",
            "type": "Numeric",
            "tags": [],
            "has_range": true,
            "range": [0, null],
            "explanation": "A lower bound for Untargeted Li perturbations to trick the classifier.\nLi attacks are bounded by the maximum value of the perturbation.",,
            "citation": "@misc{https://doi.org/10.48550/arxiv.1801.10578,\n  doi = {10.48550/ARXIV.1801.10578},\n  \n  url = {https://arxiv.org/abs/1801.10578},\n  \n  author = {Weng, Tsui-Wei and Zhang, Huan and Chen, Pin-Yu and Yi, Jinfeng and Su, Dong and Gao, Yupeng and Hsieh, Cho-Jui and Daniel, Luca},\n  \n  keywords = {Machine Learning (stat.ML), Cryptography and Security (cs.CR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  \n  title = {Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach},\n  \n  publisher = {arXiv},\n  \n  year = {2018},\n  \n  copyright = {arXiv.org perpetual, non-exclusive license}\n}\n"
        }
    }
}