<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>RAI Responsible in AI &mdash; RAI Documentation 0.1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script>let toggleHintShow = 'Click to show';</script>
        <script>let toggleHintHide = 'Click to hide';</script>
        <script>let toggleOpenOnPrint = 'true';</script>
        <script src="../_static/togglebutton.js"></script>
        <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Robustness of AI" href="Robustness%20of%20AI.html" />
    <link rel="prev" title="Installation" href="Installation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> RAI Documentation
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">User Guide:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Getting%20Started.html"><strong>Introduction</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="Getting%20Started.html#id1"><strong>Getting Started</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html"><strong>Installation</strong></a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#"><strong>RAI Responsible in AI</strong></a><ul>
<li class="toctree-l2"><a class="reference internal" href="#ethical-ai"><strong>Ethical AI</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="#robustness-and-the-adversarial-ai"><strong>Robustness and the Adversarial AI</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="#explainable-ai-aspects-of-model-development"><strong>Explainable AI aspects of model development</strong></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Robustness%20of%20AI.html"><strong>Robustness of AI</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="RAI%20in%20Model%20Selection.html"><strong>Model Selection</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="Tutorial%20Demo.html"><strong>Demo Cases</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="Dashboard.html"><strong>Dashboard</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="Basic%20component%20of%20RAI%20Design.html"><strong>Basic component of RAI Design</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="Contribute%20and%20extend%20RAI.html"><strong>Contribute and Extend RAI</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="Contribute%20and%20extend%20RAI.html#contribution-of-users-to-expand-its-features"><strong>Contribution of users to expand its features</strong></a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">RAI Documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li><strong>RAI Responsible in AI</strong></li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/RaiModule/RAI in Responsible AI.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="rai-responsible-in-ai">
<span id="rai-in-responsible-ai"></span><h1><strong>RAI Responsible in AI</strong><a class="headerlink" href="#rai-responsible-in-ai" title="Permalink to this heading"></a></h1>
<section id="ethical-ai">
<h2><strong>Ethical AI</strong><a class="headerlink" href="#ethical-ai" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p>Ethical AI Utilization</p></li>
</ul>
<blockquote>
<div><ul class="simple">
<li><p>RAI practices and adheres to well-defined ethical guidelines regarding fundamental values, including individual rights, privacy, non-discrimination, and non-manipulation.</p></li>
<li><p>It places fundamental importance on ethical considerations in determining legitimate and illegitimate uses of AI.</p></li>
<li><p>It believes integrity and ethical behavior are fundamental to a succesful AI applications.</p></li>
<li><p>It help them to dramatically improve their operations and products for humankind’s betterment.</p></li>
</ul>
</div></blockquote>
</section>
<section id="robustness-and-the-adversarial-ai">
<h2><strong>Robustness and the Adversarial AI</strong><a class="headerlink" href="#robustness-and-the-adversarial-ai" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p>Robustness and the Adversarial AI Utilization</p></li>
</ul>
<blockquote>
<div><ul class="simple">
<li><p>In the real world, AI models can encounter incidental adversity, such as when data becomes corrupted, and intentional adversity, such as when hackers actively sabotage them.</p></li>
<li><p>Both can mislead a model into delivering incorrect predictions or results.</p></li>
<li><p>Adversarial robustness refers to a model’s ability to resist being fooled.</p></li>
<li><p>RAI helps to improve the adversarial robustness of AI models, making them more impervious to irregularities and attacks.</p></li>
<li><p>RAI also focuses on the threats of Evasion (change the model behavior with input modifications), Trojaning (can access to the model and its parameters and retrain this model), Poisoning (control a model with training data modifications), Extraction (steal a model through queries) and Inference (attack the privacy of the training data).</p></li>
<li><p>RAI aims to support tasks, and data types in continuous development by defending AI against adversarial attacks and making AI systems more secure.</p></li>
</ul>
</div></blockquote>
<div class="dropdown admonition">
<p class="admonition-title">Example</p>
<p>If i give you a dataset of cat and dog photos, in which cats always wear bright red bow ties, your model may learn to associate bow ties with cats. If I give it a picture of a dog with a bow tie, your model may label it as a cat.
Adversarial machine learning also often includes identifying specific noise that can be added to inputs to confound a model. Therefore, if a model is robust, it means that it is difficult to find adversarial examples for the model.
Usually this is because the model has learned some desirable correlations (e.g. cats have a different muzzle shape than dogs), rather than undesirable ones (cats have bow ties; pictures containing cats are 0.025% more blue than those containing dogs; dog pictures have humans in them more often; etc.).
So here RAI try to directly exploit this idea, by training the model on both true data and data designed by an adversary to resemble the true data.</p>
</div>
</section>
<section id="explainable-ai-aspects-of-model-development">
<span id="contribution-to-principle-of-ai"></span><h2><strong>Explainable AI aspects of model development</strong><a class="headerlink" href="#explainable-ai-aspects-of-model-development" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p>Dashboard tools Utilization</p></li>
</ul>
<blockquote>
<div><ul class="simple">
<li><p>RAI can handle large varieties of models like text, images and tabular data.</p></li>
<li><p>It can show Analysis of the models in the dashboard.</p></li>
<li><p>Visualization can help in understanding the models so that we can have the idea of where it is failing and succeeding.</p></li>
<li><p>It can use Grad-cam to help in highlighting the important regions in the images by bound boxing.</p></li>
<li><p>RAI will show the results on the dashboard after fitting the model, allowing us to see how the model performs on Explanability, Robustness, Performance and Fairness and help us analyze how we can improve the model</p></li>
<li><p>In each category, we can check how many tests have passed and make the changes as necessary</p></li>
<li><p>Additionally, metric graphs can assist in understanding how parameter and metric changes during model development</p></li>
</ul>
</div></blockquote>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Installation.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Robustness%20of%20AI.html" class="btn btn-neutral float-right" title="Robustness of AI" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, sharfa.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>