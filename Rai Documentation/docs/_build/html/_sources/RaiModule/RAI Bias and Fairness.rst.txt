.. _RAI Bias and Fairness:

===========================
**RAI - Bias and Fairness**
===========================


The RAI goal is not to make the data unbiased or the ML model fair but to make the overall system and outcomes fair.


**How to use RAI for Bias**
===========================

- Bias in ML is an sort of mistake in which some aspects of a dataset are given more weight and/or representation than others. A skewed outcome, low accuracy levels, and analytical errors result from a dataset that is biased that does not represent a model’s use case accurately.
- RAI will use bias as the process of collecting the data to build the models. It can come with testing the outputs of the models to verify their validity. Bias can even be applied when interpreting valid or invalid results from an approved data model.


**How to use RAI for Fairness**
===============================

- Fairness in machine learning refers to the various attempts at correcting algorithmic bias in automated decision processes based on machine learning models. Decisions made by computers after a machine-learning process may be considered unfair if they were based on variables considered sensitive.
- RAI will use fairness as the process of correcting and eliminating algorithmic bias (of race and ethnicity, gender, sexual orientation, disability, and class) from machine learning models.
- If a model is trained using an unbalanced dataset, such as one that contains far more people with lighter skin than people with darker skin, there is serious risk the model’s predictions will be unfair when it is deployed.
- Here RAI enables fairness directly into the model internal representation itself to produce fair outputs even if it is trained on unfair data, which is important because there are very few well-balanced datasets for machine learning.



.. important::
    :class: dropdown

    Through RAI we can detect it before it becomes a problem or respond to it when it arises by putting the right systems in place early and staying on top of data collection, labeling, and implementation.



You can see quick Demo here - How RAi can be used for detecting and :ref:`resolving bias and fairness <Robustness of AI>` in AI models.