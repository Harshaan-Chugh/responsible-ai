{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c62ef407",
   "metadata": {},
   "source": [
    "# Image_output_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d59544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 Cisco Systems, Inc. and its affiliates\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#\n",
    "# SPDX-License-Identifier: Apache-2.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe01b514",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fbaa14",
   "metadata": {},
   "source": [
    "This demo uses Cifar10 dataset and shows how RAI can be used to evaluate image classification tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad08e6aa",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2db8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "# https://colab.research.google.com/drive/1Ozin9zX89xfoyn63o5B7l5bR5W_E1oy0#scrollTo=7hAFf5Ue4VP_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25de748",
   "metadata": {},
   "source": [
    "## Importing RAI modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7830690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RAI.AISystem import AISystem, Model\n",
    "from RAI.redis import RaiRedis\n",
    "from RAI.dataset import Dataset, Feature, MetaDatabase, NumpyData\n",
    "from RAI.utils import torch_to_RAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ce7a6",
   "metadata": {},
   "source": [
    "## Setup path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006e4181",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir)\n",
    "\n",
    "manualSeed = 42\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de68a1d6",
   "metadata": {},
   "source": [
    "## Configure a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88320c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Object(object):\n",
    "    pass\n",
    "\n",
    "config = Object()\n",
    "config.batch_size = 128\n",
    "config.epochs = 1\n",
    "config.lr = 0.0002\n",
    "config.beta1 = 0.5\n",
    "config.nz = 100\n",
    "config.ngf = 64\n",
    "config.ndf = 64\n",
    "config.ngpu = 1\n",
    "config.nc = 3\n",
    "config.image_size = 32\n",
    "config.workers = 2\n",
    "config.no_cuda = False\n",
    "config.seed = manualSeed\n",
    "config.log_interval = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314dc9a0",
   "metadata": {},
   "source": [
    "## Define Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b7865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75be25f2",
   "metadata": {},
   "source": [
    "## Defines Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5512232",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(config.nz, config.ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(config.ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(config.ngf * 8, config.ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(config.ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(config.ngf * 4, config.ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(config.ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(config.ngf * 2, config.nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh())\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4425c44c",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(config.nc, config.ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(config.ndf, config.ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(config.ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(config.ndf * 2, config.ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(config.ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(config.ndf * 4, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "def train(gen, disc, device, dataloader, optimizerG, optimizerD, criterion, epoch, iters):\n",
    "  gen.train()\n",
    "  disc.train()\n",
    "  img_list = []\n",
    "  fixed_noise = torch.randn(64, config.nz, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0a68d2",
   "metadata": {},
   "source": [
    "\n",
    "  ## Establish convention for real and fake labels during training (with label smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c1a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label = 0.9\n",
    "  fake_label = 0.1\n",
    "  for i, data in enumerate(dataloader, 0):\n",
    "      disc.zero_grad()\n",
    "      real_cpu = data[0].to(device)\n",
    "      b_size = real_cpu.size(0)\n",
    "      label = torch.full((b_size,), real_label, device=device)\n",
    "      output = disc(real_cpu).view(-1)\n",
    "      errD_real = criterion(output, label)\n",
    "      errD_real.backward()\n",
    "      D_x = output.mean().item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd71c90",
   "metadata": {},
   "source": [
    "## Train with all-fake batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc93937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(b_size, config.nz, 1, 1, device=device)\n",
    "      fake = gen(noise)\n",
    "      label.fill_(fake_label)\n",
    "      output = disc(fake.detach()).view(-1)\n",
    "      errD_fake = criterion(output, label)\n",
    "      errD_fake.backward()\n",
    "      D_G_z1 = output.mean().item()\n",
    "      errD = errD_real + errD_fake\n",
    "      optimizerD.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dceec4",
   "metadata": {},
   "source": [
    "\n",
    "   ## Update Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e19ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "  gen.zero_grad()\n",
    "      label.fill_(real_label)\n",
    "      output = disc(fake).view(-1)\n",
    "      errG = criterion(output, label)\n",
    "      errG.backward()\n",
    "      D_G_z2 = output.mean().item()\n",
    "\n",
    "      optimizerG.step()\n",
    "\n",
    "      if i % 5 == 0:\n",
    "          print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                % (epoch, config.epochs, i, len(dataloader),\n",
    "                    errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "      iters += 1\n",
    "\n",
    "#If cuda is available\n",
    "def produce_gan():\n",
    "    use_cuda = not config.no_cuda and torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e9431",
   "metadata": {},
   "source": [
    "## Set random seeds and deterministic pytorch for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb5bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(config.seed)  # python random seed\n",
    "    torch.manual_seed(config.seed)  # pytorch random seed\n",
    "    np.random.seed(config.seed)  # numpy random seed\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5244f2",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaee32ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=config.batch_size,\n",
    "                                              shuffle=True, num_workers=config.workers)\n",
    "    netG = Generator(config.ngpu).to(device)\n",
    "    if (device.type == 'cuda') and (config.ngpu > 1):\n",
    "        netG = nn.DataParallel(netG, list(range(config.ngpu)))\n",
    "    netG.apply(weights_init)\n",
    "    netD = Discriminator(config.ngpu).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7039b77b",
   "metadata": {},
   "source": [
    "   ## Handle multi-gpu if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d0d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (device.type == 'cuda') and (config.ngpu > 1):\n",
    "        netD = nn.DataParallel(netD, list(range(config.ngpu)))\n",
    "    netD.apply(weights_init)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=config.lr, betas=(config.beta1, 0.999))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=config.lr, betas=(config.beta1, 0.999))\n",
    "\n",
    "    iters = 0\n",
    "    for epoch in range(1, config.epochs + 1):\n",
    "        train(netG, netD, device, trainloader, optimizerG, optimizerD, criterion, epoch, iters)\n",
    "    torch.save(netG.state_dict(), \"cifar_gan.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4c7204",
   "metadata": {},
   "source": [
    "## Defines a main function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f9532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    use_dashboard = True\n",
    "\n",
    "    gan = Generator(config.ngpu)\n",
    "    PATH = \"./cifar_gan.h5\"\n",
    "    if not os.path.isfile(PATH):\n",
    "        print(\"Training GAN\")\n",
    "        produce_gan()\n",
    "\n",
    "    print(\"Loading model\")\n",
    "    gan.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    def generate_fake_image():\n",
    "        noise = torch.randn(1, config.nz, 1, 1)\n",
    "        return [gan(noise).detach().numpy()]\n",
    "\n",
    "    generated = None\n",
    "    for i in range(50):\n",
    "        img = generate_fake_image()\n",
    "        if generated is None:\n",
    "            generated = img\n",
    "        else:\n",
    "            generated = np.vstack((generated, img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e53d57b",
   "metadata": {},
   "source": [
    " ## Feature object for the generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d416488f",
   "metadata": {},
   "outputs": [],
   "source": [
    " output = Feature(\"Cifar Image\", \"image\", \"CIFAR Image produced by GAN\")\n",
    "    model = Model(agent=gan, output_features=output, name=\"gan\", generate_image_fun=generate_fake_image,\n",
    "                  description=\"Text Summarizer\", model_class=\"gan\")\n",
    "    configuration = {\"time_complexity\": \"polynomial\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5f8a50",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "   transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=config.batch_size, shuffle=True, num_workers=config.workers)\n",
    "    xTestData, yTestData, raw = torch_to_RAI(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f67a096",
   "metadata": {},
   "source": [
    "## Setup the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea255c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "  dataset = Dataset({\"cifar\": NumpyData(None, xTestData, raw)})\n",
    "    meta = MetaDatabase([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7344834",
   "metadata": {},
   "source": [
    "  ## Initialize RAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43834634",
   "metadata": {},
   "outputs": [],
   "source": [
    "   ai = AISystem(name=\"cifar_gan_x_y\", task='generate', meta_database=meta, dataset=dataset, model=model)\n",
    "    ai.initialize(user_config=configuration)\n",
    "    ai.compute({\"cifar\": {\"generate_image\": generated}}, tag='epoch_1_generations')\n",
    "    \n",
    "    #set up a dashboard for visualizing data related to the \"cifar\" dataset.\n",
    "    if use_dashboard:\n",
    "        r = RaiRedis(ai)\n",
    "        r.connect()\n",
    "        r.reset_redis()\n",
    "        r.add_measurement()\n",
    "        r.export_visualizations(\"cifar\", \"cifar\")\n",
    "\n",
    "    ai.display_metric_values()\n",
    "\n",
    "    from RAI.Analysis import AnalysisManager\n",
    "    analysis = AnalysisManager()\n",
    "    print(\"available analysis: \", analysis.get_available_analysis(ai, \"test\"))\n",
    "    '''\n",
    "    result = analysis.run_all(ai, \"test\", \"Test run!\")\n",
    "    for analysis in result:\n",
    "        print(\"Analysis: \" + analysis)\n",
    "        print(result[analysis].to_string())\n",
    "    '''\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
